{
    "cells": [
        {
            "cell_type": "markdown",
            "id": "729e1775aea68f89",
            "metadata": {},
            "source": [
                "# Module 6: AI for QEM (Sequence-Based LSTM)\n",
                "\n",
                "Standard ZNE assumes noise is a simple scaling function. Real noise depends on the *sequence* of gates (e.g., crosstalk, heating).\n",
                "We upgrade from simple SVR to a **Sequence-to-Scalar LSTM** that reads the actual circuit instructions."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 1,
            "id": "5cd33e6ea17b9ae7",
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Generating 2000 samples with real gate sequences...\n",
                        "  ... 0/2000\n"
                    ]
                },
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": [
                        "/Users/abdulmalekbaitulmal/Downloads/Desktop/Quanta Related/AQC/AQC Hack The Horizon/QEM Codebase/.venv/lib/python3.12/site-packages/qiskit_ibm_runtime/api/session.py:22: UserWarning: pkg_resources is deprecated as an API. See https://setuptools.pypa.io/en/latest/pkg_resources.html. The pkg_resources package is slated for removal as early as 2025-11-30. Refrain from using this package or pin to Setuptools<81.\n",
                        "  import pkg_resources\n"
                    ]
                },
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "  ... 500/2000\n",
                        "  ... 1000/2000\n",
                        "  ... 1500/2000\n",
                        "Dataset Generated.\n"
                    ]
                }
            ],
            "source": [
                "import numpy as np\n",
                "import torch\n",
                "import torch.nn as nn\n",
                "import torch.optim as optim\n",
                "from sklearn.svm import SVR\n",
                "from sklearn.pipeline import make_pipeline\n",
                "from sklearn.preprocessing import StandardScaler\n",
                "from sklearn.model_selection import train_test_split\n",
                "from qiskit_aer import AerSimulator\n",
                "from qiskit import transpile\n",
                "import utils \n",
                "\n",
                "# --- 1. Generate Dataset (Sequences + Features) ---\n",
                "DATASET_SIZE = 2000\n",
                "tokenizer = utils.CircuitTokenizer(max_length=60)\n",
                "\n",
                "X_sequences = []\n",
                "X_features = []\n",
                "y_errors = []\n",
                "\n",
                "print(f\"Generating {DATASET_SIZE} samples with real gate sequences...\")\n",
                "sim_ideal = AerSimulator(method='stabilizer')\n",
                "sim_noisy = AerSimulator(noise_model=utils.build_noise_model(scale=1.0))\n",
                "\n",
                "for i in range(DATASET_SIZE):\n",
                "    if i % 500 == 0: print(f\"  ... {i}/{DATASET_SIZE}\")\n",
                "    depth = np.random.randint(5, 50)\n",
                "    # Get Circuit AND Instructions from UTILS\n",
                "    qc, instructions = utils.create_random_clifford_circuit(2, depth)\n",
                "    \n",
                "    # Tokenize (The Real AI Part)\n",
                "    seq = tokenizer.tokenize(instructions)\n",
                "    X_sequences.append(seq)\n",
                "    \n",
                "    # Features for SVR baseline\n",
                "    ops = qc.count_ops()\n",
                "    X_features.append([depth, ops.get('cx', 0)])\n",
                "    \n",
                "    # Values\n",
                "    qc_sim = qc.copy()\n",
                "    qc_sim.measure_all()\n",
                "    # Ideal\n",
                "    res_ideal = sim_ideal.run(qc_sim, shots=1000).result()\n",
                "    counts = res_ideal.get_counts()\n",
                "    shots = sum(counts.values())\n",
                "    ideal_val = (counts.get('00',0)+counts.get('11',0) - counts.get('01',0)-counts.get('10',0))/shots\n",
                "    \n",
                "    # Noisy\n",
                "    qc_noisy = transpile(qc_sim, sim_noisy)\n",
                "    res_noisy = sim_noisy.run(qc_noisy, shots=1000).result()\n",
                "    counts_n = res_noisy.get_counts()\n",
                "    shots_n = sum(counts_n.values())\n",
                "    noisy_val = (counts_n.get('00',0)+counts_n.get('11',0) - counts_n.get('01',0)-counts_n.get('10',0))/shots_n\n",
                "    \n",
                "    y_errors.append(ideal_val - noisy_val)\n",
                "\n",
                "print(\"Dataset Generated.\")\n",
                "\n",
                "# Split\n",
                "X_seq_train, X_seq_test, X_feat_train, X_feat_test, y_train, y_test = train_test_split(\n",
                "    X_sequences, X_features, y_errors, test_size=0.2\n",
                ")\n",
                "\n",
                "# Convert to Tensors\n",
                "X_seq_train_t = torch.tensor(X_seq_train, dtype=torch.long) # Long for Embedding\n",
                "X_seq_test_t = torch.tensor(X_seq_test, dtype=torch.long)\n",
                "y_train_t = torch.tensor(y_train, dtype=torch.float32).unsqueeze(1)\n",
                "y_test_t = torch.tensor(y_test, dtype=torch.float32).unsqueeze(1)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 2,
            "id": "2de9e2cdc2b37f86",
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Training SVR Baseline...\n",
                        "SVR MSE: 0.03010\n"
                    ]
                }
            ],
            "source": [
                "# --- 2. Train Baseline SVR ---\n",
                "print(\"Training SVR Baseline...\")\n",
                "svr = make_pipeline(StandardScaler(), SVR(C=1.0, epsilon=0.01))\n",
                "svr.fit(X_feat_train, y_train)\n",
                "svr_preds = svr.predict(X_feat_test)\n",
                "svr_mse = np.mean((svr_preds - y_test)**2)\n",
                "print(f\"SVR MSE: {svr_mse:.5f}\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 3,
            "id": "cdb6a2702d65ac14",
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Training LSTM on 1600 sequences...\n",
                        "Input Shape: torch.Size([1600, 60]) (Batch, Seq_Len)\n",
                        "Epoch 0: Loss 0.02631\n",
                        "Epoch 5: Loss 0.02565\n",
                        "Epoch 10: Loss 0.02558\n",
                        "Epoch 15: Loss 0.02564\n",
                        "Epoch 20: Loss 0.02565\n",
                        "Epoch 25: Loss 0.02559\n",
                        "\n",
                        "LSTM MSE: 0.03012\n",
                        "⚠️ SVR Wins (Typical for simple noise models or small data)\n",
                        "Model saved to qem_lstm.pth\n"
                    ]
                }
            ],
            "source": [
                "# --- 3. Train Sequence LSTM ---\n",
                "class QEM_LSTM(nn.Module):\n",
                "    def __init__(self, vocab_size, embedding_dim=16, hidden_size=32):\n",
                "        super().__init__()\n",
                "        self.embedding = nn.Embedding(vocab_size, embedding_dim)\n",
                "        # batch_first=True -> (Batch, Seq, Feature)\n",
                "        self.lstm = nn.LSTM(embedding_dim, hidden_size, batch_first=True)\n",
                "        self.fc = nn.Linear(hidden_size, 1)\n",
                "        \n",
                "    def forward(self, x):\n",
                "        embeds = self.embedding(x)\n",
                "        lstm_out, _ = self.lstm(embeds)\n",
                "        # Take last time step\n",
                "        last_out = lstm_out[:, -1, :] \n",
                "        return self.fc(last_out)\n",
                "\n",
                "vocab_size = len(tokenizer.vocab) + 1 # +1 for safety\n",
                "model = QEM_LSTM(vocab_size)\n",
                "optimizer = optim.Adam(model.parameters(), lr=0.005)\n",
                "criterion = nn.MSELoss()\n",
                "\n",
                "print(f\"Training LSTM on {len(X_seq_train_t)} sequences...\")\n",
                "print(f\"Input Shape: {X_seq_train_t.shape} (Batch, Seq_Len)\")\n",
                "\n",
                "loss_history = []\n",
                "BATCH_SIZE = 32\n",
                "\n",
                "for epoch in range(30): # 30 epochs enough for demo\n",
                "    model.train()\n",
                "    # Mini-batching\n",
                "    permutation = torch.randperm(X_seq_train_t.size()[0])\n",
                "    epoch_loss = 0\n",
                "    \n",
                "    for i in range(0, X_seq_train_t.size()[0], BATCH_SIZE):\n",
                "        indices = permutation[i:i+BATCH_SIZE]\n",
                "        batch_x, batch_y = X_seq_train_t[indices], y_train_t[indices]\n",
                "        \n",
                "        optimizer.zero_grad()\n",
                "        outputs = model(batch_x)\n",
                "        loss = criterion(outputs, batch_y)\n",
                "        loss.backward()\n",
                "        optimizer.step()\n",
                "        epoch_loss += loss.item()\n",
                "        \n",
                "    avg_loss = epoch_loss / (X_seq_train_t.size()[0] / BATCH_SIZE)\n",
                "    loss_history.append(avg_loss)\n",
                "    if epoch % 5 == 0:\n",
                "        print(f\"Epoch {epoch}: Loss {avg_loss:.5f}\")\n",
                "\n",
                "# Eval\n",
                "model.eval()\n",
                "with torch.no_grad():\n",
                "    lstm_preds = model(X_seq_test_t).squeeze().numpy()\n",
                "    \n",
                "lstm_mse = np.mean((lstm_preds - y_test)**2)\n",
                "print(f\"\\nLSTM MSE: {lstm_mse:.5f}\")\n",
                "\n",
                "if lstm_mse < svr_mse:\n",
                "    print(\"✅ LSTM Wins! (Sequence learning beats feature engineering)\")\n",
                "else:\n",
                "    print(\"⚠️ SVR Wins (Typical for simple noise models or small data)\")\n",
                "    \n",
                "# Save Model\n",
                "torch.save(model.state_dict(), \"qem_lstm.pth\")\n",
                "print(\"Model saved to qem_lstm.pth\")"
            ]
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": ".venv",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "file_extension": ".py",
            "mimetype": "text/x-python",
            "name": "python",
            "nbconvert_exporter": "python",
            "pygments_lexer": "ipython3",
            "version": "3.12.7"
        },
        "orig_nbformat": 4
    },
    "nbformat": 4,
    "nbformat_minor": 5
}
